{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('../data_processing/champion_stats.csv')\n",
    "\n",
    "# Select features for clustering\n",
    "features = [\n",
    "    # Core Stats\n",
    "    'avg_kills', 'avg_deaths', 'avg_assists', 'kda',\n",
    "    'avg_kill_participation', 'avg_takedowns',\n",
    "    'avg_deaths_by_enemy_champs',\n",
    "    'winrate',\n",
    "    \n",
    "    # Damage Stats\n",
    "    'avg_dmg_dealt_to_champions', 'avg_dmg_taken',\n",
    "    'avg_magic_dmg_to_champs', 'avg_physical_dmg_to_champs', 'avg_true_dmg_to_champs',\n",
    "    'avg_dmg_self_mitigated', 'damage_per_minute',\n",
    "    'avg_largest_crit', 'avg_pct_damage_in_team', 'avg_dmg_taken_team_pct',\n",
    "    'pct_highest_dmg_in_match',\n",
    "    \n",
    "    # Support/Utility Stats\n",
    "    'avg_time_ccing_champs', 'avg_heals_on_teammate', 'avg_dmg_shielded_on_team',\n",
    "    'avg_effective_heal_and_shield', 'avg_champ_immobilizations',\n",
    "    'pct_highest_cc_in_match', 'avg_times_save_ally_from_death',\n",
    "    \n",
    "    # Economy Stats\n",
    "    'avg_gold_earned_per_game', 'avg_gold_spent', 'avg_cs',\n",
    "    'avg_neutral_monsters_cs', 'cs_per_minute', 'gold_per_minute',\n",
    "    'avg_cs_10_mins', 'avg_jg_cs_before_10m',\n",
    "    'avg_max_cs_over_lane_opp',\n",
    "    \n",
    "    # Vision Stats\n",
    "    'avg_vision_score', 'avg_wards_placed', 'avg_wards_killed', 'avg_ctrl_wards_bought',\n",
    "    'avg_ctrol_wards_placed', 'avg_vision_score_per_min', 'pct_highest_ward_kills_in_match',\n",
    "    'avg_ctrl_ward_time_coverage_in_river_or_enemy_half',\n",
    "    \n",
    "    # Objective Stats\n",
    "    'pct_of_games_team_took_first_baron', 'pct_of_games_team_took_first_drag', \n",
    "    'pct_of_games_team_took_first_turret', 'pct_games_team_took_first_herald',\n",
    "    'avg_indiv_dmg_dealt_to_buildings', 'avg_dmg_dealt_to_objs', 'avg_indiv_turret_plates_taken',\n",
    "    'avg_epic_monster_steals', 'avg_epic_monster_kills_within_30s_of_spawn',\n",
    "    \n",
    "    # Jungle Stats\n",
    "    'avg_buffs_stolen', 'avg_initial_buff_count', 'avg_initial_crab_count',\n",
    "    'avg_crabs_per_game', 'avg_jgler_kills_early_jungle',\n",
    "    'avg_jgler_early_kills_on_laners',\n",
    "    \n",
    "    # Survival Stats\n",
    "    'avg_longest_time_alive', 'avg_bounty_lvl', 'avg_time_spent_dead',\n",
    "    'avg_times_survived_single_digit_hp', 'avg_times_survived_3_immobilizes_in_fight',\n",
    "    'avg_times_took_large_dmg_survived',\n",
    "    \n",
    "    # Early Game Stats\n",
    "    'pct_of_games_with_early_lanephase_gold_exp_adv', 'pct_of_games_with_lanephase_gold_exp_adv',\n",
    "    'avg_max_lvl_lead_lane_opp', 'pct_games_first_blood_kill', 'pct_of_games_indiv_killed_1st_tower',\n",
    "    \n",
    "    # Multikill Stats\n",
    "    'avg_killing_sprees', 'avg_largest_killing_spee', 'avg_number_of_multikills',\n",
    "    'avg_multikills_with_one_spell', 'avg_legendary_count'\n",
    "]\n",
    "\n",
    "# Check which features exist in the dataframe\n",
    "available_features = [f for f in features if f in df.columns]\n",
    "missing_features = [f for f in features if f not in df.columns]\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"Warning: The following features are not in the dataset and will be skipped: {missing_features}\")\n",
    "\n",
    "# Use only available features\n",
    "features = available_features\n",
    "\n",
    "# Prepare the data\n",
    "X = df[features].copy()\n",
    "\n",
    "# Check for NaN values\n",
    "nan_counts = X.isna().sum()\n",
    "print(\"\\nColumns with NaN values:\")\n",
    "print(nan_counts[nan_counts > 0])\n",
    "\n",
    "# Handle missing values by imputing with mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Now standardize the imputed data\n",
    "X = StandardScaler().fit_transform(X_imputed)\n",
    "\n",
    "# Elbow method to find optimal number of clusters\n",
    "inertias = []\n",
    "K = range(1, 20)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K, inertias, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()\n",
    "\n",
    "# Perform k-means clustering\n",
    "n_clusters = 12  # You can adjust this based on the elbow plot\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Analyze PCA components\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Calculate explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Plot explained variance ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), cumulative_variance_ratio, 'bo-')\n",
    "plt.axhline(y=0.80, color='r', linestyle='--', label='80% Threshold')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio by PCA Components')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find number of components needed for 80% variance\n",
    "n_components_80 = np.argmax(cumulative_variance_ratio >= 0.80) + 1\n",
    "print(f\"Number of components needed to explain 80% of variance: {n_components_80}\")\n",
    "\n",
    "# Create visualization using first 3 components (if we have enough dimensions)\n",
    "if X_pca.shape[1] >= 3:\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                        c=df['Cluster'], cmap='viridis')\n",
    "    ax.set_xlabel('First Principal Component')\n",
    "    ax.set_ylabel('Second Principal Component')\n",
    "    ax.set_zlabel('Third Principal Component')\n",
    "    plt.title('Champion-Role Clusters (3D)')\n",
    "    \n",
    "    # Add champion-role names as annotations\n",
    "    for i, champ_role in enumerate(df['champ_role']):\n",
    "        ax.text(X_pca[i, 0], X_pca[i, 1], X_pca[i, 2], champ_role, fontsize=8)\n",
    "    \n",
    "    plt.colorbar(scatter)\n",
    "    plt.show()\n",
    "\n",
    "# Calculate cluster means\n",
    "cluster_means = df.groupby('Cluster')[features].mean()\n",
    "\n",
    "# Print clusters and their characteristics\n",
    "for cluster in range(n_clusters):\n",
    "    print(f\"\\n=== Cluster {cluster} ===\")\n",
    "    print(\"\\nChampion-Roles in this cluster:\")\n",
    "    cluster_champs = df[df['Cluster'] == cluster]['champ_role'].tolist()\n",
    "    print(', '.join(sorted(cluster_champs)))\n",
    "    \n",
    "    print(\"\\nDistinctive features:\")\n",
    "    cluster_features = cluster_means.loc[cluster]\n",
    "    sorted_features = cluster_features.sort_values(ascending=False)\n",
    "    print(sorted_features.head())\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data (using existing X from previous code)\n",
    "clustering_methods = {\n",
    "    'K-Means': KMeans(n_clusters=5, random_state=42),\n",
    "    'DBSCAN': DBSCAN(eps=2.5, min_samples=3),\n",
    "    'Hierarchical': AgglomerativeClustering(n_clusters=5),\n",
    "    'Gaussian Mixture': GaussianMixture(n_components=5, random_state=42)\n",
    "}\n",
    "\n",
    "# Compare clustering methods\n",
    "plt.figure(figsize=(20, 5))\n",
    "for idx, (name, model) in enumerate(clustering_methods.items(), 1):\n",
    "    plt.subplot(1, 4, idx)\n",
    "    \n",
    "    # Fit the model\n",
    "    if name == 'Gaussian Mixture':\n",
    "        labels = model.fit_predict(X)\n",
    "    else:\n",
    "        labels = model.fit_predict(X)\n",
    "    \n",
    "    # Calculate silhouette score (except for DBSCAN which might have -1 labels)\n",
    "    if name != 'DBSCAN':\n",
    "        score = silhouette_score(X, labels)\n",
    "        print(f\"{name} Silhouette Score: {score:.3f}\")\n",
    "    \n",
    "    # Plot first two PCA components colored by cluster\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis')\n",
    "    plt.title(f'{name} Clustering')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Hierarchical Clustering, show dendrogram\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "linkage_matrix = linkage(X, 'ward')\n",
    "dendrogram(linkage_matrix, labels=df['champ_role'].values)\n",
    "plt.title('Champion-Role Hierarchy Dendrogram')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# For Gaussian Mixture, show probability distribution\n",
    "if 'Gaussian Mixture' in clustering_methods:\n",
    "    gmm = clustering_methods['Gaussian Mixture']\n",
    "    probs = gmm.predict_proba(X)\n",
    "    \n",
    "    # Show champion-roles with highest mixture of playstyles\n",
    "    hybrid_scores = -np.sum(probs * np.log(probs + 1e-10), axis=1)  # entropy\n",
    "    most_hybrid = pd.DataFrame({\n",
    "        'Champion-Role': df['champ_role'],\n",
    "        'Hybrid Score': hybrid_scores\n",
    "    }).sort_values('Hybrid Score', ascending=False)\n",
    "    \n",
    "    print(\"\\nMost Hybrid Champion-Roles (highest mixture of playstyles):\")\n",
    "    print(most_hybrid.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more detailed cluster profile\n",
    "def analyze_cluster_profiles(df, cluster_means, features, n_clusters):\n",
    "    # Create a dictionary to store cluster profiles\n",
    "    cluster_profiles = {}\n",
    "    \n",
    "    # Calculate global means and standard deviations\n",
    "    global_means = df[features].mean()\n",
    "    global_stds = df[features].std()\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        # Get champions in this cluster\n",
    "        cluster_champs = df[df['Cluster'] == cluster]['champ_role'].tolist()\n",
    "        \n",
    "        # Calculate z-scores for this cluster's means\n",
    "        cluster_means_series = cluster_means.loc[cluster]\n",
    "        z_scores = (cluster_means_series - global_means) / global_stds\n",
    "        \n",
    "        # Sort features by absolute z-score\n",
    "        sorted_features = z_scores.abs().sort_values(ascending=False)\n",
    "        \n",
    "        # Store cluster profile\n",
    "        cluster_profiles[cluster] = {\n",
    "            'champion_roles': sorted(cluster_champs),\n",
    "            'size': len(cluster_champs),\n",
    "            'distinctive_features': {\n",
    "                feature: {\n",
    "                    'z_score': z_scores[feature],\n",
    "                    'mean': cluster_means_series[feature],\n",
    "                    'global_mean': global_means[feature]\n",
    "                }\n",
    "                for feature in sorted_features.index[:10]  # Top 10 most distinctive features\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return cluster_profiles\n",
    "\n",
    "# Generate cluster profiles\n",
    "cluster_profiles = analyze_cluster_profiles(df, cluster_means, features, n_clusters)\n",
    "\n",
    "# Function to visualize cluster features\n",
    "def visualize_cluster_features(cluster_profiles, cluster_to_visualize=None):\n",
    "    if cluster_to_visualize is not None:\n",
    "        clusters_to_show = [cluster_to_visualize]\n",
    "    else:\n",
    "        clusters_to_show = list(cluster_profiles.keys())\n",
    "    \n",
    "    for cluster in clusters_to_show:\n",
    "        profile = cluster_profiles[cluster]\n",
    "        \n",
    "        print(f\"\\n=== Cluster {cluster} ===\")\n",
    "        print(f\"Size: {profile['size']} champion-roles\")\n",
    "        print(\"\\nChampion-Roles in this cluster:\")\n",
    "        print(', '.join(profile['champion_roles']))\n",
    "        \n",
    "        print(\"\\nDistinctive Features:\")\n",
    "        features_df = pd.DataFrame.from_dict(profile['distinctive_features'], orient='index')\n",
    "        \n",
    "        # Create a bar plot of z-scores\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        features_df['z_score'].plot(kind='bar')\n",
    "        plt.title(f'Distinctive Features for Cluster {cluster}')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed statistics\n",
    "        print(\"\\nDetailed Statistics:\")\n",
    "        for feature, stats in profile['distinctive_features'].items():\n",
    "            print(f\"{feature}:\")\n",
    "            print(f\"  Z-score: {stats['z_score']:.2f}\")\n",
    "            print(f\"  Cluster mean: {stats['mean']:.2f}\")\n",
    "            print(f\"  Global mean: {stats['global_mean']:.2f}\")\n",
    "            print()\n",
    "\n",
    "# Function to find similar champion-roles\n",
    "def find_similar_champion_roles(champ_role_name, n=5):\n",
    "    if champ_role_name not in df['champ_role'].values:\n",
    "        print(f\"Champion-Role '{champ_role_name}' not found in the dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Get the features for the target champion-role\n",
    "    target_features = X[df['champ_role'] == champ_role_name].flatten()\n",
    "    \n",
    "    # Calculate Euclidean distances to all other champion-roles\n",
    "    distances = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['champ_role'] != champ_role_name:\n",
    "            dist = np.linalg.norm(X[idx] - target_features)\n",
    "            distances.append((row['champ_role'], dist))\n",
    "    \n",
    "    # Sort by distance and get top N\n",
    "    similar_champs = sorted(distances, key=lambda x: x[1])[:n]\n",
    "    \n",
    "    print(f\"\\nMost similar champion-roles to {champ_role_name}:\")\n",
    "    for champ, dist in similar_champs:\n",
    "        print(f\"{champ}: Distance = {dist:.2f}\")\n",
    "\n",
    "# Function to recommend champion-roles based on preferences\n",
    "def recommend_champion_roles_by_preferences(preferences, cluster_profiles, cluster_descriptions, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend champion-roles based on player preferences.\n",
    "    \n",
    "    preferences: dict of feature preferences, e.g., {'damage_per_minute': 1, 'avg_vision_score': 0.5}\n",
    "    cluster_profiles: output from analyze_cluster_profiles\n",
    "    cluster_descriptions: dict mapping cluster numbers to playstyle descriptions\n",
    "    top_n: number of recommendations to return\n",
    "    \"\"\"\n",
    "    # Calculate preference scores for each cluster\n",
    "    cluster_scores = {}\n",
    "    for cluster, profile in cluster_profiles.items():\n",
    "        score = 0\n",
    "        for feature, weight in preferences.items():\n",
    "            if feature in profile['distinctive_features']:\n",
    "                score += profile['distinctive_features'][feature]['z_score'] * weight\n",
    "        cluster_scores[cluster] = score\n",
    "    \n",
    "    # Get the best matching clusters\n",
    "    best_clusters = sorted(cluster_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    # Get champion-roles from the best clusters\n",
    "    recommendations = []\n",
    "    for cluster, score in best_clusters:\n",
    "        champ_roles = cluster_profiles[cluster]['champion_roles']\n",
    "        playstyle = cluster_descriptions.get(cluster, \"Unknown playstyle\")\n",
    "        recommendations.extend([(champ_role, playstyle, score) for champ_role in champ_roles])\n",
    "    \n",
    "    # Sort by cluster score and return top N\n",
    "    recommendations.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    print(\"\\nRecommended champion-roles based on your preferences:\")\n",
    "    for champ_role, playstyle, score in recommendations[:top_n]:\n",
    "        print(f\"{champ_role} - {playstyle} (Score: {score:.2f})\")\n",
    "\n",
    "# Save the cluster profiles and descriptions\n",
    "import pickle\n",
    "\n",
    "# Save cluster profiles\n",
    "with open('champion_cluster_profiles.pkl', 'wb') as f:\n",
    "    pickle.dump(cluster_profiles, f)\n",
    "\n",
    "# Create and save cluster descriptions (you would need to manually create these based on analysis)\n",
    "cluster_descriptions = {\n",
    "    # Example descriptions - these should be updated based on actual analysis\n",
    "    0: \"High damage carries\",\n",
    "    1: \"Utility supports\",\n",
    "    2: \"Tank initiators\",\n",
    "    # ... add descriptions for all clusters\n",
    "}\n",
    "\n",
    "with open('champion_cluster_descriptions.pkl', 'wb') as f:\n",
    "    pickle.dump(cluster_descriptions, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this visualization to better understand what defines each cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_cluster_features(cluster_profiles, cluster_to_visualize=None):\n",
    "    if cluster_to_visualize is not None:\n",
    "        clusters_to_show = [cluster_to_visualize]\n",
    "    else:\n",
    "        clusters_to_show = list(cluster_profiles.keys())\n",
    "    \n",
    "    for cluster in clusters_to_show:\n",
    "        profile = cluster_profiles[cluster]\n",
    "        \n",
    "        # Combine high and low features\n",
    "        all_features = pd.concat([profile['distinctive_high'], profile['distinctive_low']])\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        bars = plt.barh(all_features.index, all_features.values, color=['green' if x > 0 else 'red' for x in all_features.values])\n",
    "        plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.title(f'Cluster {cluster} Distinctive Features (Z-scores)')\n",
    "        plt.xlabel('Z-score (standard deviations from mean)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Visualize all clusters or a specific one\n",
    "visualize_cluster_features(cluster_profiles)\n",
    "# Or for a specific cluster: visualize_cluster_features(cluster_profiles, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to understand relationships between clusters\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Calculate distances between cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "cluster_distances = squareform(pdist(cluster_centers))\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "cluster_distance_df = pd.DataFrame(\n",
    "    cluster_distances, \n",
    "    index=[f'Cluster {i}' for i in range(n_clusters)],\n",
    "    columns=[f'Cluster {i}' for i in range(n_clusters)]\n",
    ")\n",
    "\n",
    "# Visualize as a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cluster_distance_df, annot=True, cmap='viridis')\n",
    "plt.title('Distance Between Cluster Centers')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find the closest clusters for each cluster\n",
    "for i in range(n_clusters):\n",
    "    # Get distances to other clusters (excluding self)\n",
    "    distances = cluster_distances[i]\n",
    "    distances[i] = np.inf  # Exclude self\n",
    "    \n",
    "    # Find the 3 closest clusters\n",
    "    closest_indices = np.argsort(distances)[:3]\n",
    "    closest_distances = distances[closest_indices]\n",
    "    \n",
    "    print(f\"\\nCluster {i} is most similar to:\")\n",
    "    for idx, dist in zip(closest_indices, closest_distances):\n",
    "        print(f\"  Cluster {idx} (distance: {dist:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to find similar champions across the dataset\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Calculate distances between all champions\n",
    "champion_distances = euclidean_distances(X_imputed)\n",
    "\n",
    "# Create a DataFrame with champion names\n",
    "champion_distance_df = pd.DataFrame(\n",
    "    champion_distances,\n",
    "    index=df['championName'],\n",
    "    columns=df['championName']\n",
    ")\n",
    "\n",
    "# Function to find similar champions\n",
    "def find_similar_champions(champion_name, n=5):\n",
    "    if champion_name not in champion_distance_df.index:\n",
    "        print(f\"Champion {champion_name} not found!\")\n",
    "        return\n",
    "    \n",
    "    # Get distances to all other champions\n",
    "    distances = champion_distance_df.loc[champion_name]\n",
    "    \n",
    "    # Sort and get the closest ones (excluding self)\n",
    "    similar_champions = distances.sort_values()[1:n+1]\n",
    "    \n",
    "    print(f\"Champions most similar to {champion_name}:\")\n",
    "    for champ, dist in similar_champions.items():\n",
    "        print(f\"  {champ} (distance: {dist:.2f})\")\n",
    "    \n",
    "    return similar_champions\n",
    "\n",
    "# Example usage\n",
    "find_similar_champions('Ahri')\n",
    "find_similar_champions('Darius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this after analyzing the clusters\n",
    "cluster_descriptions = {\n",
    "    0: {\n",
    "        \"name\": \"Tanky Frontliners\",\n",
    "        \"description\": \"Champions who excel at absorbing damage and providing crowd control for their team.\",\n",
    "        \"playstyle\": \"These champions typically build defensive items and focus on initiating fights and protecting allies.\",\n",
    "        \"strengths\": [\"High survivability\", \"Good crowd control\", \"Team fight presence\"],\n",
    "        \"weaknesses\": [\"Lower damage output\", \"Can be kited\", \"Dependent on team follow-up\"],\n",
    "        \"recommended_for\": \"Players who enjoy being in the middle of fights and protecting their team.\"\n",
    "    },\n",
    "    # Add more clusters with detailed descriptions\n",
    "}\n",
    "\n",
    "# Save these descriptions for your chat agent\n",
    "with open('champion_cluster_descriptions.pkl', 'wb') as f:\n",
    "    pickle.dump(cluster_descriptions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_champions_by_preferences(preferences, cluster_profiles, cluster_descriptions, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend champions based on user preferences.\n",
    "    \n",
    "    Parameters:\n",
    "    - preferences: dict of feature preferences (e.g., {'damage': 'high', 'survivability': 'medium'})\n",
    "    - cluster_profiles: the cluster profiles generated earlier\n",
    "    - cluster_descriptions: human-readable descriptions of clusters\n",
    "    - top_n: number of champions to recommend\n",
    "    \n",
    "    Returns:\n",
    "    - List of recommended champions with explanations\n",
    "    \"\"\"\n",
    "    # Map user preferences to features\n",
    "    feature_mapping = {\n",
    "        'damage': ['totalDamageDealtToChampions', 'damage_per_minute'],\n",
    "        'survivability': ['totalDamageTaken', 'damageSelfMitigated', 'longestTimeSpentLiving'],\n",
    "        'utility': ['timeCCingOthers', 'totalHealsOnTeammates', 'totalDamageShieldedOnTeammates'],\n",
    "        'mobility': ['challenges_quickSoloKills', 'challenges_survivedSingleDigitHpCount'],\n",
    "        'farming': ['cs_per_minute', 'gold_per_minute'],\n",
    "        # Add more mappings\n",
    "    }\n",
    "    \n",
    "    # Score each cluster based on preferences\n",
    "    cluster_scores = {}\n",
    "    for cluster_id, profile in cluster_profiles.items():\n",
    "        score = 0\n",
    "        for pref, value in preferences.items():\n",
    "            if pref in feature_mapping:\n",
    "                relevant_features = feature_mapping[pref]\n",
    "                \n",
    "                # Calculate average z-score for relevant features\n",
    "                feature_scores = []\n",
    "                for feature in relevant_features:\n",
    "                    if feature in profile['raw_means']:\n",
    "                        # Find this feature's z-score\n",
    "                        if feature in profile['distinctive_high'].index:\n",
    "                            z_score = profile['distinctive_high'][feature]\n",
    "                        elif feature in profile['distinctive_low'].index:\n",
    "                            z_score = profile['distinctive_low'][feature]\n",
    "                        else:\n",
    "                            # If not in distinctive features, it's close to average\n",
    "                            z_score = 0\n",
    "                        \n",
    "                        feature_scores.append(z_score)\n",
    "                \n",
    "                if feature_scores:\n",
    "                    avg_score = sum(feature_scores) / len(feature_scores)\n",
    "                    \n",
    "                    # Adjust score based on preference value\n",
    "                    if value == 'high' and avg_score > 0:\n",
    "                        score += avg_score\n",
    "                    elif value == 'low' and avg_score < 0:\n",
    "                        score += abs(avg_score)\n",
    "                    elif value == 'medium' and abs(avg_score) < 0.5:\n",
    "                        score += 1 - abs(avg_score)\n",
    "        \n",
    "        cluster_scores[cluster_id] = score\n",
    "    \n",
    "    # Get top clusters\n",
    "    top_clusters = sorted(cluster_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    # Get champions from top clusters\n",
    "    recommendations = []\n",
    "    for cluster_id, score in top_clusters:\n",
    "        cluster_champs = cluster_profiles[cluster_id]['champions']\n",
    "        \n",
    "        # Add explanation from cluster description\n",
    "        explanation = cluster_descriptions.get(cluster_id, {}).get('description', \n",
    "                                                                 f\"Champions from cluster {cluster_id}\")\n",
    "        \n",
    "        # Add some champions from this cluster\n",
    "        champs_to_add = min(top_n // len(top_clusters) + 1, len(cluster_champs))\n",
    "        for champ in cluster_champs[:champs_to_add]:\n",
    "            recommendations.append({\n",
    "                'champion': champ,\n",
    "                'cluster': cluster_id,\n",
    "                'cluster_score': score,\n",
    "                'explanation': explanation\n",
    "            })\n",
    "    \n",
    "    # Return top N recommendations\n",
    "    return sorted(recommendations, key=lambda x: x['cluster_score'], reverse=True)[:top_n]\n",
    "\n",
    "# Example usage\n",
    "preferences = {\n",
    "    'damage': 'high',\n",
    "    'survivability': 'medium',\n",
    "    'utility': 'low',\n",
    "    'mobility': 'high'\n",
    "}\n",
    "\n",
    "recommendations = recommend_champions_by_preferences(\n",
    "    preferences, \n",
    "    cluster_profiles, \n",
    "    cluster_descriptions\n",
    ")\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(f\"{rec['champion']} - {rec['explanation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
